{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bd4287",
   "metadata": {},
   "source": [
    "# Admin Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa08e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.4' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# We install these packages first to allow connectivity to the remote database\n",
    "\n",
    "!pip install sqlalchemy\n",
    "!pip install PyMySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420e2dd",
   "metadata": {},
   "source": [
    "## STEP 1 Use SQL to successfully retrieve dataset from remote Heicoders database, using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82d015",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "\n",
    "ENDPOINT = 'heicoders-playground.c2ced10ceyki.ap-southeast-1.rds.amazonaws.com'\n",
    "PORT = 3306\n",
    "USERNAME = 'student300'\n",
    "PASSWORD = 'heicoders_AI300'\n",
    "DBNAME = 'ai300_capstone'\n",
    "\n",
    "database_conn = create_engine(f'mysql+pymysql://{USERNAME}:{PASSWORD}@{ENDPOINT}/{DBNAME}')\n",
    "\n",
    "## STEP 2 Use SQL to retrieve at least one column\n",
    "\n",
    "## To verify columns against data dictionary.\n",
    "\n",
    "query_account = \"\"\"\n",
    "    SELECT * FROM account;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_account_usage = \"\"\"\n",
    "    SELECT * FROM account_usage;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_churn = \"\"\"\n",
    "    SELECT * FROM churn_status;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_customer = \"\"\"\n",
    "    SELECT * FROM customer;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_city = \"\"\"\n",
    "    SELECT * FROM city;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_1 = pd.read_sql(query_account, database_conn)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_sql(query_account_usage, database_conn)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_sql(query_churn, database_conn)\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.read_sql(query_customer, database_conn)\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.read_sql(query_city, database_conn)\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e3a19",
   "metadata": {},
   "source": [
    "## STEP 2 - Extract at least one column per table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "query_account_col = \"\"\"\n",
    "    SELECT account_id, tenure_months FROM account;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_account_usage_col = \"\"\"\n",
    "    SELECT stream_tv,stream_movie FROM account_usage;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_churn_col = \"\"\"\n",
    "    SELECT churn_label, churn_category FROM churn_status;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_customer_col = \"\"\"\n",
    "    SELECT gender,age,married FROM customer;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query_city_col = \"\"\"\n",
    "    SELECT area_id, zip_code, city FROM city;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_6 = pd.read_sql(query_account_col, database_conn)\n",
    "df_7 = pd.read_sql(query_account_usage_col, database_conn)\n",
    "df_8 = pd.read_sql(query_churn_col, database_conn)\n",
    "df_9 = pd.read_sql(query_customer_col, database_conn)\n",
    "df_10 = pd.read_sql(query_city_col, database_conn)\n",
    "df_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb659a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc85af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ab552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To merge all tables\n",
    "\n",
    "merged_churn = \"\"\"\n",
    "    Select \n",
    "    b.account_id, b.customer_id, b.tenure_months, b.num_referrals, \n",
    "    b.has_internet_service, b.internet_type,b.has_unlimited_data,b.has_phone_service, \n",
    "    b.has_multiple_lines, b.has_premium_tech_support, b.has_online_security, b.has_online_backup, \n",
    "    b.has_device_protection, b.contract_type, b.paperless_billing, b.payment_method,\n",
    "    a.status, a.churn_label, a.churn_category,a.churn_reason,\n",
    "    c.avg_long_distance_fee_monthly,c.total_long_distance_fee,c.avg_gb_download_monthly,\n",
    "    c.stream_tv,c.stream_movie,c.stream_music,c.total_monthly_fee,c.total_charges_quarter,c.total_refunds,\n",
    "    d.gender,d.age,d.senior_citizen,d.married,d.num_dependents,\n",
    "    e.area_id,e.zip_code,e.city,e.latitutde,e.longitude,e.population\n",
    "    From churn_status as a\n",
    "    Left join account as b On a.customer_id = b.customer_id\n",
    "    Left join account_usage as c On b.account_id = c.account_id\n",
    "    Left join customer as d On a.customer_id = d.customer_id\n",
    "    Left join city as e On d.zip_code = e.zip_code;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_churn_table = pd.read_sql(merged_churn, database_conn)\n",
    "df_churn_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c0616",
   "metadata": {},
   "source": [
    "## STEP 3 Visualise the data using matplotlib/plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4959838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import visualisation packages like plotly and matplotlib here\n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install folium\n",
    "\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137470d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph 1: I hypothesised that we should not expect people <65 years old to churn credit cards\n",
    "## as they are still working and need credit cards to manage cash flow. \n",
    "\n",
    "sbn.histplot(df_churn_table, x='age',hue='status')\n",
    "\n",
    "## Notice in the histogram that people approaching and ust past the age of 50 years old is churning more than the other groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph 2: I also hypothesised that those who will churn will likely have a shorter tenure duration, \n",
    "## and they would have spent less than those who stayed as they are likely opportunistic in pursuing promotions elsewhere.\n",
    "\n",
    "fig = px.histogram(df_churn_table, \n",
    "                   x = 'tenure_months',\n",
    "                   y = 'total_long_distance_fee',\n",
    "                   color = 'status',\n",
    "                   marginal = 'box' # or violin, rug\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e4ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a74284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph X: I hypothesised that people living in specific parts of the country could be suggesitble to churn due to\n",
    "## cultural norms and expectations. So I crafted\n",
    "\n",
    "print(df_churn_table['longitude'].min())\n",
    "print(df_churn_table['longitude'].max())\n",
    "print(df_churn_table['latitutde'].min())\n",
    "print(df_churn_table['latitutde'].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c5a3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e4fb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below used to make a scatterplot visualisation that yielded no meaningful trend and only clutter. \n",
    "\n",
    "# To save if code is needed again.Avoid scatterplots in the meanwhile.\n",
    "\n",
    "\n",
    "# ## fig = px.scatter(df_churn_table,\n",
    "#                  x='age',\n",
    "#                  y='tenure_months',\n",
    "#                  color='gender'\n",
    "# )\n",
    "\n",
    "# fig.update_yaxes(title_text=\"tenure_months\", ticksuffix=\" months\")\n",
    "# fig.update_xaxes(title_text=\"Age\", ticksuffix=\" years\")\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b5960",
   "metadata": {},
   "source": [
    "## STEP 4 Perform Feature Engineering on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7207c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages for this segment\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_table.isnull().sum()\n",
    "\n",
    "## Null cell check round 1, but it looks like there is nothing despite there being null cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn_table == '').sum()\n",
    "\n",
    "## Discovered empty string cells in churn_label, churn_category and churn_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeac910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3.loc[df_3[\"churn_reason\"] == \"\"].head(50))\n",
    "print(df_3.loc[df_3[\"churn_reason\"] == \"\"].tail(50))\n",
    "print(df_3.loc[df_3[\"churn_category\"] == \"\"].head(50))\n",
    "print(df_3.loc[df_3[\"churn_category\"] == \"\"].tail(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f937c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[df_3[\"churn_label\"] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f701d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.loc[df_3[\"churn_label\"] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce68038",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looking further at the columns with empty string, we decided to drop some rows just for \"churn_label\".\n",
    "## This is because the reasons for churning are beyond the company's control. \n",
    "## We decided to ignore cleaning \"churn_category\" and \"churn_reason\" as the vast majority (>30%) of cells are empty. \n",
    "\n",
    "\n",
    "##Dropping the columns\n",
    "\n",
    "df_churn_revised = df_churn_table.drop(columns=['churn_category','churn_reason'])\n",
    "\n",
    "\n",
    "##Dropping rows for blank churn_labels\n",
    "df_churn_clean =df_churn_revised[df_churn_revised['churn_label'] != \"\"]\n",
    "df_churn_revised[df_churn_revised['churn_label'] != \"\"]\n",
    "df_churn_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e929f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will keep the following fields unchanged:\n",
    "## account - account_id, customer_id, tenure_months, num_referrals\n",
    "## account_usage - account_id, avg_long_distance, total_long_distance_fee, avg_gb_download_monthly, \n",
    "## account_usage - total_monthly_fee, total_chargers_quarter, total_refunds\n",
    "## Churn_status - customer_id, churn_category (removed), churn_reason (removed)\n",
    "## customer - Customer_id, age, num_dependents, zip_code\n",
    "## city - area_id, zip_code, latitude, longitutde, population\n",
    "\n",
    "## Using label encoding by table of origin for variables with only two options.\n",
    "\n",
    "## Account\n",
    "\n",
    "df_churn_clean2 = df_churn_clean.copy()\n",
    "\n",
    "cols = ['has_internet_service','has_unlimited_data','has_phone_service','has_multiple_lines','has_premium_tech_support'\n",
    "       ,'has_online_security','has_online_backup','has_device_protection','paperless_billing','stream_tv',\n",
    "        'stream_movie','stream_music','churn_label','gender','senior_citizen','married']\n",
    "\n",
    "for col in cols:\n",
    "    df_churn_clean2[col] = df_churn_clean[col].replace({'Yes':1,'No':0})\n",
    "    \n",
    "df_churn_clean2['gender'] = df_churn_clean['gender'].replace({'Male':1,'Female':0})\n",
    "\n",
    "# df_churn_clean['has_internet_service'] = label_encoder.fit_transform(df_churn_clean['has_internet_service'])\n",
    "# df_churn_clean['has_unlimited_data'] = label_encoder.fit_transform(df_churn_clean['has_unlimited_data'])\n",
    "# df_churn_clean['has_phone_service'] = label_encoder.fit_transform(df_churn_clean['has_phone_service'])\n",
    "# df_churn_clean['has_multiple_lines'] = label_encoder.fit_transform(df_churn_clean['has_multiple_lines'])\n",
    "# df_churn_clean['has_premium_tech_support'] = label_encoder.fit_transform(df_churn_clean['has_premium_tech_support'])\n",
    "# df_churn_clean['has_online_security'] = label_encoder.fit_transform(df_churn_clean['has_online_security'])\n",
    "# df_churn_clean['has_online_backup'] = label_encoder.fit_transform(df_churn_clean['has_online_backup'])\n",
    "# df_churn_clean['has_device_protection'] = label_encoder.fit_transform(df_churn_clean['has_device_protection'])\n",
    "# df_churn_clean['paperless_billing'] = label_encoder.fit_transform(df_churn_clean['paperless_billing'])\n",
    "\n",
    "# Has_internet_service – change to boolean (1,0)\n",
    "# Has_unlimited_data – change to boolean (1,0)\n",
    "# Has_phone_service – change to boolean (1,0)\n",
    "# Has_multiple_lines – change to boolean (1,0)\n",
    "# Has_premium_tech_support – change to boolean (1,0)\n",
    "# Has_online_security – change to boolean (1,0)\n",
    "# Has_online_backup – change to boolean (1,0)\n",
    "# Has_device_protection – change to boolean (1,0)\n",
    "# paperless_billing – change to boolean (1,0)\n",
    "\n",
    "## Account_usage\n",
    "\n",
    "# df_churn_clean['stream_tv'] = label_encoder.fit_transform(df_churn_clean['stream_tv'])\n",
    "# df_churn_clean['stream_movie'] = label_encoder.fit_transform(df_churn_clean['stream_movie'])\n",
    "# df_churn_clean['stream_music'] = label_encoder.fit_transform(df_churn_clean['stream_music'])\n",
    "\n",
    "# Stream_tv - change to boolean (1,0)\n",
    "# Stream_movie - change to boolean (1,0)\n",
    "# Stream_music - change to boolean (1,0)\n",
    "\n",
    "\n",
    "# ## Churn_status\n",
    "# df_churn_clean['churn_label'] = label_encoder.fit_transform(df_churn_clean['churn_label'])\n",
    "# # Churn_label – change to boolean\n",
    "\n",
    "# # ## Customer\n",
    "# df_churn_clean['gender'] = label_encoder.fit_transform(df_churn_clean['gender'])\n",
    "# df_churn_clean['senior_citizen'] = label_encoder.fit_transform(df_churn_clean['senior_citizen'])\n",
    "# df_churn_clean['married'] = label_encoder.fit_transform(df_churn_clean['married'])\n",
    "# Gender - change to boolean (1,0)\n",
    "# Senior_citizen - change to boolean (1,0)\n",
    "# married - change to boolean (1,0)\n",
    "\n",
    "df_churn_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f1da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21341ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using one-hot encoding by table of origin for variables with more than 2 answers\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "\n",
    "## Account\n",
    "internet_type_OH = pd.get_dummies(df_churn_clean['internet_type'],dtype=int)\n",
    "contract_type_OH = pd.get_dummies(df_churn_clean['contract_type'],dtype=int)\n",
    "payment_method_OH = pd.get_dummies(df_churn_clean['payment_method'],dtype=int)\n",
    "\n",
    "\n",
    "# Internet type – change to categorical (1,2,3,4)\n",
    "# Contract_type – change to categorical (1,2,3)\n",
    "# Payment_ method – change to categorical (1,2,3)\n",
    "\n",
    "## Account_usage - None\n",
    "\n",
    "## Churn_status\n",
    "\n",
    "status_OH = pd.get_dummies(df_churn_clean['status'],dtype=int)\n",
    "\n",
    "\n",
    "\n",
    "# status – change to categorical (0 for joined, 1 for stayed, 2 for leave)\n",
    "\n",
    "# City Label encoding due to 'object' variable\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_churn_clean2['city'] = label_encoder.fit_transform(df_churn_clean2['city'])\n",
    "\n",
    "## Customer - None\n",
    "\n",
    "df_fin_churn = pd.concat([df_churn_clean2,internet_type_OH,contract_type_OH,payment_method_OH,status_OH], axis=1)\n",
    "df_fin_churn.drop(['internet_type','contract_type','payment_method','status'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9122ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_churn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079301fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_churn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_fin_churn.corr(numeric_only=True)\n",
    "fig = px.imshow(corr, color_continuous_scale = 'Brwnyl', text_auto = True)\n",
    "fig.update_xaxes(side=\"top\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dced88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_churn['churn_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69374181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_churn['city']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68fb00",
   "metadata": {},
   "source": [
    "## STEP 5-7 CREATE A MODEL FOR LOGISTIC REGRESSION using train test split and GridsearchCV to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e63e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## field test for hyperparameter tuning - XGB\n",
    "\n",
    "features= df_fin_churn.columns.drop(['churn_label','account_id','customer_id'])\n",
    "\n",
    "X = df_fin_churn[['tenure_months','has_unlimited_data','has_premium_tech_support','has_device_protection','total_monthly_fee']]\n",
    "y = df_fin_churn['churn_label'].values\n",
    "\n",
    "xgb_model = XGBClassifier(random_state = 5)\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\": [100,200,500],\n",
    "    \"max_depth\" : [3, 6, 9],\n",
    "    'gamma' : [0.01, 0.1],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(estimator = xgb_model,\n",
    "            param_grid = search_space,\n",
    "            scoring = 'roc_auc',\n",
    "             cv = 5,\n",
    "             verbose = 4            \n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "GS.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed142f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "\n",
    "\n",
    "# Split data into predictors X and output Y\n",
    "\n",
    "features= df_fin_churn.columns.drop(['churn_label','account_id','customer_id'])\n",
    "\n",
    "\n",
    "X = df_fin_churn[['tenure_months','has_unlimited_data','has_premium_tech_support','has_device_protection','total_monthly_fee']] \n",
    "y = df_fin_churn['churn_label'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg_model = log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_test,y_pred)\n",
    "print('AUC:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test with XGboost with standard parameters\n",
    "X = df_fin_churn[['tenure_months','has_unlimited_data','has_premium_tech_support','has_device_protection','total_monthly_fee']] \n",
    "y = df_fin_churn['churn_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "xgboost_model = XGBClassifier(learning_rate=0.1,random_state=5)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = xgboost_model.predict_proba(X_test)[:,1]\n",
    "auc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print('AUC:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test with XGboost with suggested hyperparameter tested parameters\n",
    "X = df_fin_churn[['tenure_months','has_unlimited_data','has_premium_tech_support','has_device_protection','total_monthly_fee']] \n",
    "y = df_fin_churn['churn_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "xgboost_model = XGBClassifier(n_estimators = 500, max_depth=3, learning_rate = 0.01, random_state=5)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = xgboost_model.predict_proba(X_test)[:,1]\n",
    "auc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print('AUC:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6026f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with CatBoost\n",
    "\n",
    "\n",
    "X = df_fin_churn[['tenure_months','has_unlimited_data','has_premium_tech_support','has_device_protection','total_monthly_fee']] \n",
    "y = df_fin_churn['churn_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "catboost_model = CatBoostClassifier(learning_rate= 0.01, depth=3, random_state=5)\n",
    "catboost_model.fit(X_train, y_train, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = catboost_model.predict_proba(X_test)[:,1]\n",
    "auc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print('AUC:', auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c367be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with CatBoost with higher depth, learning rate and random_state\n",
    "\n",
    "\n",
    "\n",
    "X = df_fin_churn[['tenure_months','has_unlimited_data','has_premium_tech_support','has_device_protection','total_monthly_fee']] \n",
    "y = df_fin_churn['churn_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "catboost_model = CatBoostClassifier(learning_rate= 0.1, depth=5, random_state=10)\n",
    "catboost_model.fit(X_train, y_train, verbose=False)\n",
    "                  \n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = catboost_model.predict_proba(X_test)[:,1]\n",
    "auc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print('AUC:', auc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13d069",
   "metadata": {},
   "source": [
    "Conclusion: Use Catboost with parameters: learning_rate= 0.01, depth=3, random_state=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb17af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_fin_churn[['tenure_months','has_unlimited_data','has_premium_tech_support','has_device_protection','total_monthly_fee']] \n",
    "y = df_fin_churn['churn_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "catboost_model_final = CatBoostClassifier(learning_rate= 0.01, depth=3, random_state=5)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(catboost_model_final, '../model/catboost_model_final.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b8411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
